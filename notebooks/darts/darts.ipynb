{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip3 install darts plotly wandb python-dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline\n",
    "\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "os.environ['WANDB_NOTEBOOK_NAME'] = 'pytorch_stats_own_data.ipynb'\n",
    "os.environ['WANDB_API_KEY'] = os.getenv('WANDB_API_KEY')\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "\n",
    "from darts import TimeSeries\n",
    "from darts.models import NBEATSModel\n",
    "from darts.dataprocessing.transformers import Scaler, MissingValuesFiller\n",
    "from darts.metrics import mape, r2_score\n",
    "\n",
    "from darts import TimeSeries\n",
    "\n",
    "from darts.datasets import EnergyDataset\n",
    "\n",
    "import helper\n",
    "import glob\n",
    "\n",
    "from pytorch_lightning.loggers import WandbLogger\n",
    "wandb_logger = WandbLogger(project=\"Digital-Energy\")\n",
    "\n",
    "\n",
    "AVAILABLE_GPUS = torch.cuda.device_count()\n",
    "AVAILABLE_CPUS = os.cpu_count()\n",
    "\n",
    "print(f\"Available GPUs: {AVAILABLE_GPUS}\")\n",
    "print(f\"Available CPUs: {AVAILABLE_CPUS}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read a pandas DataFrame\n",
    "# df = pd.read_parquet('../../Data/ldn_df2.parquet')\n",
    "# df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../../Data/london_clean/cleaned_household_MAC000002.csv')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df.drop(['Unnamed: 0'], axis=1, inplace=True)\n",
    "df.drop(['StdorToU'], axis=1 , inplace=True)\n",
    "df.drop(['TimeOfDay'], axis=1 , inplace=True)\n",
    "df.drop([\"LCLid\"], axis=1, inplace=True)\n",
    "df['DateTime'] = pd.to_datetime(df['DateTime'])\n",
    "df = df.loc[~df[\"DateTime\"].duplicated(), :]\n",
    "df.rename(columns={'KWH/hh (per half hour) ': 'KWH'} , inplace=True)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "df = pd.concat([pd.read_csv(x) for x in sorted(glob.glob(\"../../Data/london_clean/*.csv\"))[:20]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df['LCLid'] = df['LCLid'].apply(lambda x: x[3:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Check for missing values in the dataset\n",
    "import glob\n",
    "sum = 0\n",
    "f = open('../../missing.txt', 'w')\n",
    "for i, x in enumerate(sorted (glob.glob(\"../../Data/london_clean/*.csv\"))):\n",
    "    df = pd.read_csv(x)\n",
    "    if not helper.find_gaps(df).empty:\n",
    "        print(f'{i}: {x} has gaps')\n",
    "        f.write(f'{x}\\n{helper.find_gaps(df)}\\n-----------------------\\n')\n",
    "        sum += 1\n",
    "print (sum)\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "helper.find_gaps(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"DateTime\"] = df[\"index\"].apply(lambda x: df[\"DateTime\"][0] + (x * pd.Timedelta(minutes=30)))\n",
    "df[\"DateTime\"] = df[\"DateTime\"].apply(lambda x: x.strftime(\"%Y-%m-%d\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_max = df.groupby(df[\"DateTime\"].astype(str).str.split(\" \").str[0]).max()\n",
    "filler = MissingValuesFiller()\n",
    "scaler = Scaler()\n",
    "series = scaler.fit_transform(\n",
    "    filler.transform(\n",
    "        TimeSeries.from_dataframe(df_max, \"DateTime\", [\"KWH\"])\n",
    "    )\n",
    ").astype(np.float32)\n",
    "series.plot()\n",
    "plt.title(\"Daily peak usage in household\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating training data\n",
    "\n",
    "Darts only takes its own timeseries as input. so we have to generate this first"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Create data from \n",
    "\n",
    "my_time_series_dataset = []\n",
    "for x in sorted(glob.glob(\"../../Data/london_clean/*.csv\"))[:20]:\n",
    "    series = TimeSeries.from_csv(x, time_col='DateTime', value_cols='KWHhh')\n",
    "    my_time_series_dataset.append(series)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## old\n",
    "# series = TimeSeries.from_dataframe(df_max, value_cols=['KWH'], time_col=\"index\", fill_missing_dates=True)\n",
    "\n",
    "## 2 different ways of splitting train and test\n",
    "# train, val = series.split_after(0.85)\n",
    "#train, val = series[:-48], series[-48:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_sets = []\n",
    "validation_sets = []\n",
    "for x in my_time_series_dataset:\n",
    "    train, val = series.split_after(0.85)\n",
    "    training_sets.append(train)\n",
    "    validation_sets.append(val)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_sets[0].plot(label=\"training\")\n",
    "validation_sets[0].plot(label=\"validation\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_nbeats = NBEATSModel(\n",
    "    input_chunk_length=30,\n",
    "    output_chunk_length=7,\n",
    "    generic_architecture=True,\n",
    "    num_stacks=10,\n",
    "    num_blocks=1,\n",
    "    num_layers=3,\n",
    "    layer_widths=512,\n",
    "    n_epochs=50,\n",
    "    nr_epochs_val_period=1,\n",
    "    batch_size=400,\n",
    "    work_dir=\"../../Models\",\n",
    "    save_checkpoints=True,\n",
    "    model_name=\"nbeats_run\",\n",
    "    pl_trainer_kwargs={\n",
    "      \"accelerator\": \"gpu\",\n",
    "      \"devices\": 1,\n",
    "      \"logger\": wandb_logger\n",
    "    },\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_nbeats.fit(series=training_sets, val_series=validation_sets, verbose=True, num_loader_workers=AVAILABLE_CPUS)\n",
    "# model_nbeats.save_model(\"../../Models/test.pth.tar\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (optional) load model from file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_nbeats = NBEATSModel.load_model(\"../../Models/nbeats_run/_model.pth.tar\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Validate\n",
    "\n",
    "We create unseen data and then do a historical forecast to see how well the model does."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(600,605):\n",
    "    plt.figure(figsize=(20,10))\n",
    "    df = pd.read_csv(f'../../Data/london_clean/cleaned_household_MAC000{i}.csv')\n",
    "    series = TimeSeries.from_dataframe(df, value_cols=['KWHhh'], time_col=\"DateTime\", fill_missing_dates=True)\n",
    "    series = series[-150:]\n",
    "    # save the plot\n",
    "    series.plot(label=f\"Household {i}\")\n",
    "    plt.legend()\n",
    "    plt.savefig(f'../../Plots/Household_{i}.png')\n",
    "    plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(f'../../Data/london_clean/cleaned_household_MAC000600.csv')\n",
    "# take the max KWH value from each day\n",
    "df[\"DateTime\"] = pd.to_datetime(df['DateTime'])\n",
    "df = df.groupby(pd.Grouper(key='DateTime', freq='1D')).max().round(3).reset_index()\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_series = model_nbeats.historical_forecasts(\n",
    "    series,\n",
    "    forecast_horizon=1,\n",
    "    stride=2,\n",
    "    retrain=False,\n",
    "    verbose=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from darts.metrics import mape, r2_score, rmse\n",
    "\n",
    "# print(f\"Mean absolute percentage error: {mape(series, pred_series)}.\")\n",
    "print(f\"rmse: {rmse(series, pred_series)}.\")\n",
    "print(f\"R2 score: {r2_score(series, pred_series)}.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "helper.display_forecast(pred_series, series, \"1 day\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "ac2eaa0ea0ebeafcc7822e65e46aa9d4f966f30b695406963e145ea4a91cd4fc"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
